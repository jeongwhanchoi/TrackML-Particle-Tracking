{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from trackml.dataset import load_event, load_dataset\n",
    "from trackml.score import score_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this according to your directory preferred setting\n",
    "path_to_train = \"./input/train_5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on one event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This event is in Train_1\n",
    "event_prefix = \"event000008180\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and Look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits, cells, particles, truth = load_event(os.path.join(path_to_train, event_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hit_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>volume_id</th>\n",
       "      <th>layer_id</th>\n",
       "      <th>module_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-64.895897</td>\n",
       "      <td>-9.09471</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-62.720901</td>\n",
       "      <td>-5.21209</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-76.973999</td>\n",
       "      <td>-6.18337</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-83.017097</td>\n",
       "      <td>-1.09181</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-73.857498</td>\n",
       "      <td>-10.65260</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hit_id          x         y       z  volume_id  layer_id  module_id\n",
       "0       1 -64.895897  -9.09471 -1502.5          7         2          1\n",
       "1       2 -62.720901  -5.21209 -1502.5          7         2          1\n",
       "2       3 -76.973999  -6.18337 -1502.5          7         2          1\n",
       "3       4 -83.017097  -1.09181 -1502.5          7         2          1\n",
       "4       5 -73.857498 -10.65260 -1502.5          7         2          1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify tracks\n",
    "In this example the track pattern recognition is solved as clustering problem. Each of the clusters corresponds to one track. Firstly we preprocess hit coordinates in order to highlight the fact that a track is (approximatly) an arc of helix.\n",
    "\n",
    "$$r_1=\\sqrt{x^2+y^2+z^2}$$\n",
    " \n",
    "$$x_2=x/r_1$$\n",
    " \n",
    "$$y_2=y/r_1$$\n",
    " \n",
    "$$r_2=\\sqrt{x^2+y^2}$$\n",
    " \n",
    "$$z_2=z/r_2$$\n",
    " \n",
    "Then, DBSCAN is used to recognize hit clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from collections import Sequence\n",
    "\n",
    "\"\"\"\n",
    "updated - added self.rz_scale\n",
    "\"\"\"\n",
    "class Clusterer(object):\n",
    "    \n",
    "    def __init__(self, eps):\n",
    "        self.eps = eps\n",
    "        self.rz_scale = 1\n",
    "        \n",
    "    \n",
    "    def _preprocess(self, hits):\n",
    "        \n",
    "        x = hits.x.values\n",
    "        y = hits.y.values\n",
    "        z = hits.z.values\n",
    "\n",
    "        r = np.sqrt(x**2 + y**2 + z**2)\n",
    "        hits['x2'] = x/r\n",
    "        hits['y2'] = y/r\n",
    "\n",
    "        r = np.sqrt(x**2 + y**2)\n",
    "        hits['z2'] = z/r\n",
    "\n",
    "        ss = StandardScaler()\n",
    "        X = ss.fit_transform(hits[['x2', 'y2', 'z2']].values)\n",
    "        X[:,2] = X[:,2] * self.rz_scale\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    \n",
    "    def predict(self, hits, rz_scale=1):\n",
    "        \n",
    "        self.rz_scale = rz_scale\n",
    "        X = self._preprocess(hits)\n",
    "        \n",
    "        cl = DBSCAN(eps=self.eps, min_samples=1, algorithm='kd_tree')\n",
    "        labels = cl.fit_predict(X)\n",
    "        \n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "updated - added to predict: rz_scale=1.5\n",
    "\"\"\"\n",
    "model = Clusterer(eps=0.008)\n",
    "labels = model.predict(hits, rz_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     1     2 ... 72039 72040 72041]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score\n",
    "Compute the score for this event. The dummy submission output of create_one_event_submission is created only to be the second parameter of the score_event function. It should not be confused with a well-behaved submission for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_event_submission(event_id, hits, labels):\n",
    "    sub_data = np.column_stack(([event_id]*len(hits), hits.hit_id.values, labels))\n",
    "    submission = pd.DataFrame(data=sub_data, columns=[\"event_id\", \"hit_id\", \"track_id\"]).astype(int)\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = create_one_event_submission(0, hits, labels)\n",
    "score = score_event(truth, submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your score:  0.19775939010865784\n"
     ]
    }
   ],
   "source": [
    "print(\"Your score: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognize tracks in all events of a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recognize tracks in all events of a dataset\n",
    "In this example, the dataset is the whole training set.\n",
    "This is a simple loop over the one-event actions: because of the use of DBScan, there is no actual training.\n",
    "\n",
    "This may take a very long time. To run on only a subset, use\n",
    "\n",
    "``` python\n",
    "load_dataset(path_to_train, skip=1000, nevents=5)\n",
    "```\n",
    "\n",
    "It will skip the first 1000 events, and select the next 5 ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for event 8180: 0.198\n",
      "Score for event 8181: 0.212\n",
      "Score for event 8182: 0.222\n",
      "Score for event 8183: 0.210\n",
      "Score for event 8184: 0.205\n",
      "Mean score: 0.209\n"
     ]
    }
   ],
   "source": [
    "dataset_submissions = []\n",
    "dataset_scores = []\n",
    "\n",
    "for event_id, hits, cells, particles, truth in load_dataset(path_to_train, skip=0, nevents=5):\n",
    "        \n",
    "    # Track pattern recognition\n",
    "    model = Clusterer(eps=0.008)\n",
    "    labels = model.predict(hits, rz_scale=1.5)\n",
    "        \n",
    "    # Prepare submission for an event\n",
    "    one_submission = create_one_event_submission(event_id, hits, labels)\n",
    "    dataset_submissions.append(one_submission)\n",
    "    \n",
    "    # Score for the event\n",
    "    score = score_event(truth, one_submission)\n",
    "    dataset_scores.append(score)\n",
    "    \n",
    "    print(\"Score for event %d: %.3f\" % (event_id, score))\n",
    "    \n",
    "print('Mean score: %.3f' % (np.mean(dataset_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creat a sumbmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID:  0\n",
      "Event ID:  1\n",
      "Event ID:  2\n",
      "Event ID:  3\n",
      "Event ID:  4\n",
      "Event ID:  5\n",
      "Event ID:  6\n",
      "Event ID:  7\n",
      "Event ID:  8\n",
      "Event ID:  9\n",
      "Event ID:  10\n",
      "Event ID:  11\n",
      "Event ID:  12\n",
      "Event ID:  13\n",
      "Event ID:  14\n",
      "Event ID:  15\n",
      "Event ID:  16\n",
      "Event ID:  17\n",
      "Event ID:  18\n",
      "Event ID:  19\n",
      "Event ID:  20\n",
      "Event ID:  21\n",
      "Event ID:  22\n",
      "Event ID:  23\n",
      "Event ID:  24\n",
      "Event ID:  25\n",
      "Event ID:  26\n",
      "Event ID:  27\n",
      "Event ID:  28\n",
      "Event ID:  29\n",
      "Event ID:  30\n",
      "Event ID:  31\n",
      "Event ID:  32\n",
      "Event ID:  33\n",
      "Event ID:  34\n",
      "Event ID:  35\n",
      "Event ID:  36\n",
      "Event ID:  37\n",
      "Event ID:  38\n",
      "Event ID:  39\n",
      "Event ID:  40\n",
      "Event ID:  41\n",
      "Event ID:  42\n",
      "Event ID:  43\n",
      "Event ID:  44\n",
      "Event ID:  45\n",
      "Event ID:  46\n",
      "Event ID:  47\n",
      "Event ID:  48\n",
      "Event ID:  49\n",
      "Event ID:  50\n",
      "Event ID:  51\n",
      "Event ID:  52\n",
      "Event ID:  53\n",
      "Event ID:  54\n",
      "Event ID:  55\n",
      "Event ID:  56\n",
      "Event ID:  57\n",
      "Event ID:  58\n",
      "Event ID:  59\n",
      "Event ID:  60\n",
      "Event ID:  61\n",
      "Event ID:  62\n",
      "Event ID:  63\n",
      "Event ID:  64\n",
      "Event ID:  65\n",
      "Event ID:  66\n",
      "Event ID:  67\n",
      "Event ID:  68\n",
      "Event ID:  69\n",
      "Event ID:  70\n",
      "Event ID:  71\n",
      "Event ID:  72\n",
      "Event ID:  73\n",
      "Event ID:  74\n",
      "Event ID:  75\n",
      "Event ID:  76\n",
      "Event ID:  77\n",
      "Event ID:  78\n",
      "Event ID:  79\n",
      "Event ID:  80\n",
      "Event ID:  81\n",
      "Event ID:  82\n",
      "Event ID:  83\n",
      "Event ID:  84\n",
      "Event ID:  85\n",
      "Event ID:  86\n",
      "Event ID:  87\n",
      "Event ID:  88\n",
      "Event ID:  89\n",
      "Event ID:  90\n",
      "Event ID:  91\n",
      "Event ID:  92\n",
      "Event ID:  93\n",
      "Event ID:  94\n",
      "Event ID:  95\n",
      "Event ID:  96\n",
      "Event ID:  97\n",
      "Event ID:  98\n",
      "Event ID:  99\n",
      "Event ID:  100\n",
      "Event ID:  101\n",
      "Event ID:  102\n",
      "Event ID:  103\n",
      "Event ID:  104\n",
      "Event ID:  105\n",
      "Event ID:  106\n",
      "Event ID:  107\n",
      "Event ID:  108\n",
      "Event ID:  109\n",
      "Event ID:  110\n",
      "Event ID:  111\n",
      "Event ID:  112\n",
      "Event ID:  113\n",
      "Event ID:  114\n",
      "Event ID:  115\n",
      "Event ID:  116\n",
      "Event ID:  117\n",
      "Event ID:  118\n",
      "Event ID:  119\n",
      "Event ID:  120\n",
      "Event ID:  121\n",
      "Event ID:  122\n",
      "Event ID:  123\n",
      "Event ID:  124\n"
     ]
    }
   ],
   "source": [
    "path_to_test = \"./input/test\"\n",
    "test_dataset_submissions = []\n",
    "\n",
    "create_submission = True # True for submission \n",
    "\n",
    "if create_submission:\n",
    "    for event_id, hits, cells in load_dataset(path_to_test, parts=['hits', 'cells']):\n",
    "\n",
    "        # Track pattern recognition\n",
    "        model = Clusterer(eps=0.008)\n",
    "        labels = model.predict(hits, rz_scale=1.5)\n",
    "\n",
    "        # Prepare submission for an event\n",
    "        one_submission = create_one_event_submission(event_id, hits, labels)\n",
    "        test_dataset_submissions.append(one_submission)\n",
    "        \n",
    "        print('Event ID: ', event_id)\n",
    "\n",
    "    # Create submission file\n",
    "    submussion = pd.concat(test_dataset_submissions, axis=0)\n",
    "    submussion.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
